{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d16da-03d7-4120-ba2f-8b4d862e98d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12175,
     "status": "ok",
     "timestamp": 1705696990978,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "fd5d16da-03d7-4120-ba2f-8b4d862e98d5",
    "outputId": "15439a89-6ecb-4536-d06d-c6d7cec89c58"
   },
   "outputs": [],
   "source": [
    "# installing langchain, for more info see: https://python.langchain.com/docs/get_started/installation\n",
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db56e3b-46b6-45de-bfe0-d490e78eb07d",
   "metadata": {},
   "source": [
    "### Importing the libraries we'll need moving forward, for more info see: https://python.langchain.com/docs/integrations/llms/huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-e6cO33AjsI4",
   "metadata": {
    "executionInfo": {
     "elapsed": 4624,
     "status": "ok",
     "timestamp": 1705696995597,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "-e6cO33AjsI4"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb58809-1a3a-495d-9111-37fe7a840c97",
   "metadata": {
    "executionInfo": {
     "elapsed": 4624,
     "status": "ok",
     "timestamp": 1705696995597,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "-e6cO33AjsI4"
   },
   "source": [
    "###  We first need to get an API token from HuggingFace, see: https://python.langchain.com/docs/integrations/llms/huggingface_hub. Replace it below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a6e90-1edd-4538-b44a-1384a6b1592e",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1705696995598,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "a20a6e90-1edd-4538-b44a-1384a6b1592e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"XXXXXXXXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d882f89-3fb3-4c5d-b7e5-ac58e2569cea",
   "metadata": {},
   "source": [
    "### Zero shot template, we want to have placeholders for the prompt, since we'll test a few of them and for the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77472795-4a04-43d3-8dd8-6d8f4a76c0c9",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1705696995598,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "77472795-4a04-43d3-8dd8-6d8f4a76c0c9"
   },
   "outputs": [],
   "source": [
    "zero_shot_template = \"\"\"{prompt}. If the action cannot be accomplished using the information provided answer with \"I don't know\".\n",
    "\n",
    "Context: Personally identifiable information (PII) is any data that could identify a specific person, such as credit card numbers, government-issued ID number, date of birth, telephone, login details, social security number (SSN) or address.\n",
    "\n",
    "Q: {query}\n",
    "\n",
    "A: \"\"\"\n",
    "\n",
    "zero_shot_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"prompt\",\"query\"],\n",
    "    template=zero_shot_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad64fa2-2f2f-4e6d-8213-e5c914290da1",
   "metadata": {},
   "source": [
    "### Here I chose to use mistral https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1 but you can choose any of the models listed under:https://huggingface.co/models?pipeline_tag=text-generation\n",
    "In fact, you should potentially test a few models but that's outside of the scope of this post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93586f95-f264-4301-8880-247e7ef1b39a",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1705696995598,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "93586f95-f264-4301-8880-247e7ef1b39a"
   },
   "outputs": [],
   "source": [
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf274db-91ee-426d-9af8-25bb3d37d695",
   "metadata": {},
   "source": [
    "### Creating the llm, I chose temperature .1 since we need the model to be as factual as possible. For more information on temperature, please see https://txt.cohere.com/llm-parameters-best-outputs-language-ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bbe091-17f4-4e75-b2a3-4d874271e50e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1705696996224,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "f2bbe091-17f4-4e75-b2a3-4d874271e50e",
    "outputId": "7ad24678-61f7-4236-e933-bab0e934cb23"
   },
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    repo_id=repo_id, model_kwargs={\"temperature\": 0.1, \"max_length\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dpHHfbBwof3z",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1705696996224,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "dpHHfbBwof3z"
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=zero_shot_prompt_template, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a95538-b66e-4224-814f-77366156c0cc",
   "metadata": {},
   "source": [
    "### Testing a few examples manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25jOtOBoogCN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1705696997164,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "25jOtOBoogCN",
    "outputId": "87dde171-d20d-4d6d-bb60-3163e790e2ef"
   },
   "outputs": [],
   "source": [
    "print(llm_chain.run(prompt=\"Identify PII information in the text and provide it as the output\",\n",
    "        query=\"My credit card number is 23424234234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa831fb7-59fe-43c4-bdd6-d411706f51a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1458,
     "status": "ok",
     "timestamp": 1705696998616,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "fa831fb7-59fe-43c4-bdd6-d411706f51a0",
    "outputId": "9a147ced-fb40-45fe-df2c-dd5145c1dd5f"
   },
   "outputs": [],
   "source": [
    "print(llm_chain.run(prompt=\"Detect PII information in the text\",\n",
    "        query=\"My SSN is 23424234234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b34455-4a88-4253-8de7-f3af9bc43631",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1705696998616,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "88b34455-4a88-4253-8de7-f3af9bc43631",
    "outputId": "9275400b-2095-4144-cfcc-89c591ae9b29"
   },
   "outputs": [],
   "source": [
    "print(llm_chain.run(prompt=\"Identify PII information in the text and return such values\",\n",
    "        query=\"676-233-4234 is my phone number\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce81beb-c3e4-44e8-a550-82c4d0d4f86c",
   "metadata": {},
   "source": [
    "### Creating a few shot prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yj_5cjfXm4al",
   "metadata": {
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1705696998753,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "yj_5cjfXm4al"
   },
   "outputs": [],
   "source": [
    "# few-shot\n",
    "few_shot_template = \"\"\"{prompt}. If the action cannot be accomplished using the information provided answer with \"I don't know\".\n",
    "\n",
    "Context: Personally identifiable information (PII) is any data that could identify a specific person, such as credit card numbers, government-issued ID number, date of birth, telephone, login details, social security number (SSN) or address.\n",
    "Q: My social security number is 23424234234\n",
    "A: 23424234234\n",
    "\n",
    "Q: Here's my credit card number 2123-1231-2312-1231\n",
    "A: 2123-1231-2312-1231\n",
    "\n",
    "Q: Send it to my address 1221 Massachusetts AVE NW\n",
    "A: 1221 Massachusetts AVE NW\n",
    "\n",
    "Q: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "few_shot_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"prompt\",\"query\"],\n",
    "    template=few_shot_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RmDzfWyLoYiU",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1705696998753,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "RmDzfWyLoYiU"
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=few_shot_prompt_template, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60162ef7-0016-4503-8c95-9284fbda04cd",
   "metadata": {},
   "source": [
    "### Again testing a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P2F4vHiEopWG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3800,
     "status": "ok",
     "timestamp": 1705697002551,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "P2F4vHiEopWG",
    "outputId": "c9af0588-615d-4bbb-d259-9aac8369e40f"
   },
   "outputs": [],
   "source": [
    "print(llm_chain.run(prompt=\"Identify PII information in the text and provide it as the output\",\n",
    "        query=\"My credit card number is 23424234234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MCkqJ_U-osRl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4901,
     "status": "ok",
     "timestamp": 1705697007427,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "MCkqJ_U-osRl",
    "outputId": "7b7f3503-accc-4a22-b523-4ce7221e3eab"
   },
   "outputs": [],
   "source": [
    "print(llm_chain.run(prompt=\"Detect PII information in the text\",\n",
    "        query=\"My SSN is 23424234234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ATfc8Msyo2OE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1705697007427,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "ATfc8Msyo2OE",
    "outputId": "c403f650-2da6-4b74-d454-ece86658c0b1"
   },
   "outputs": [],
   "source": [
    "print(llm_chain.run(prompt=\"Identify PII information in the text and return such values\",\n",
    "        query=\"786-709-8545 is my phone number\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3361b85-ffde-4bba-bbcb-7d6bab6a2426",
   "metadata": {},
   "source": [
    "## Now the meat of if, I'm going to create a function that iterates through the prompts and demonstration set and provides the accuracy for each prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "itYkBCpm98LT",
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1705697007428,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "itYkBCpm98LT"
   },
   "outputs": [],
   "source": [
    "prompts = [\"Identify PII information in the text and provide it as the output\", \"Detect PII information in the text\", \"Identify PII information in the text and return such values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YXiEW15c-GjH",
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1705697007428,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "YXiEW15c-GjH"
   },
   "outputs": [],
   "source": [
    "queries = {\n",
    "    \"My social security number is 23424234234\" : \"23424234234\",\n",
    "    \"Here's my credit card number 2123-1231-2312-1231\" : \"2123-1231-2312-1231\",\n",
    "    \"Send it to my address 234432 Indiana AVE SE\" : \"234432 Indiana AVE SE\",\n",
    "    \"786-709-8545 is my phone number\" : \"786-709-8545\",\n",
    "    \"I ate the veggie bowl\" : \"I don't know\",\n",
    "    \"Mi numero the pasaporte es A78369\" : \"A78369\",\n",
    "    \"cesar_dummy@gmail.com\" : \"cesar_dummy@gmail.com\",\n",
    "    \"My birthday is in two weeks\" : \"I don't know\",\n",
    "    \"isfgk9482SD is the password\" : \"I don't know\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eKqdfSfNETGk",
   "metadata": {
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1705697189683,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "eKqdfSfNETGk"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(prompt_template, llm, prompts, queries):\n",
    "  llm_chain = LLMChain(prompt=prompt_template, llm=llm)\n",
    "  accuracy_per_prompt = { prompt: 0 for prompt in prompts}\n",
    "  for prompt in prompts:\n",
    "    for query,answer in queries.items():\n",
    "      prediction = llm_chain.run(prompt=prompt, query=query).strip()\n",
    "      prediction = prediction.strip(\".\")\n",
    "      print(\"Prediction: {}, Correct Answer: {}\\n\".format(prediction, answer))\n",
    "      if prediction == answer:\n",
    "        accuracy_per_prompt[prompt] += 1\n",
    "    accuracy_per_prompt[prompt] = accuracy_per_prompt[prompt] / len(queries)\n",
    "  return accuracy_per_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d90d1a5-ccc3-482f-a6e9-c058203b047a",
   "metadata": {},
   "source": [
    "### Testing the accuracy for zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jdmwdTWsFzUv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "executionInfo": {
     "elapsed": 965,
     "status": "error",
     "timestamp": 1705697192323,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "jdmwdTWsFzUv",
    "outputId": "397bb8e3-6b76-4d9c-e58f-5a6cc059dfef"
   },
   "outputs": [],
   "source": [
    "# zero-shot\n",
    "zero_shot_accuracy_per_prompt = check_accuracy(zero_shot_prompt_template, llm, prompts, queries)\n",
    "for prompt, accuracy in zero_shot_accuracy_per_prompt.items():\n",
    "  print(\"{}: Accuracy for prompt {} is {}\\n\".format(\"Zero-shot\", prompt, round(accuracy*100,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ddff2f-ca2c-4d59-a111-63f281376177",
   "metadata": {},
   "source": [
    "### Testing the accuracy for few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HbP_FiCWGl7o",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1045,
     "status": "ok",
     "timestamp": 1705697099509,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "HbP_FiCWGl7o",
    "outputId": "247f7f34-1fbd-42ce-b7e2-b4d98ece7dcc"
   },
   "outputs": [],
   "source": [
    "few_shot_accuracy_per_prompt = check_accuracy(few_shot_prompt_template, llm, prompts, queries, \"Few-Shot\")\n",
    "for prompt, accuracy in zero_shot_accuracy_per_prompt.items():\n",
    "  print(\"{}: Accuracy for prompt {} is {}\\n\".format(\"Few-shot\", prompt, round(accuracy*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1783d2-4e1c-4c4d-ae53-5137e177524a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1705697009500,
     "user": {
      "displayName": "cesar carlos calderon",
      "userId": "00633334589948425614"
     },
     "user_tz": 360
    },
    "id": "77u9i3Vtc5-M"
   },
   "source": [
    "### As you can see, the prompt number 3 gives us 100% accuracy for both zero shot and few shot. Since we also have to consider cost when we are picking the best prompt, in this case we'll go with the zero shot approach since it uses less tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c40335-875d-4651-86c9-9b5733007412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
